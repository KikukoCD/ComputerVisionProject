{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "INFOCV_ActionRecogniton_of.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "c5hcihlK9PwZ"
   },
   "source": [
    "!nvidia-smi"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tU_WwR2DeJpI"
   },
   "source": [
    "#@title WANDB Login { run: \"auto\", display-mode: \"form\" }\n",
    "wandbapi = \"\" #@param {type:\"string\"}\n",
    "!pip install wandb > /dev/null\n",
    "!wandb login \"$wandbapi\"\n",
    "%env USE_WANDB=1"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_6JrPNVUYjZu"
   },
   "source": [
    "%cd /content/INFOMCV/\n",
    "!git pull origin master"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uoquSwALcOuI"
   },
   "source": [
    "!pip install -r requirements.txt > /dev/null"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "NB15LtU0sbBc"
   },
   "source": [
    "#@title Load cached dataset from google drive\n",
    "drive_project_root = \"MyDrive/Colab2/INFOCV\" #@param {type:\"string\"}\n",
    "dataset_name = \"tvhi_augmented.tar.gz\" #@param {type:\"string\"}\n",
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "drive_dataset_dir = os.path.join('/content/drive', drive_project_root)\n",
    "drive_dataset_path = os.path.join('/content/drive', drive_project_root, dataset_name)\n",
    "\n",
    "!mkdir -p $drive_dataset_dir\n",
    "!test -e $drive_dataset_path \\\n",
    "  && echo 'Extracting the cached dataset' \\\n",
    "  && cp $drive_dataset_path $dataset_name \\\n",
    "  && tar -xzf $dataset_name"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "G7yB_NEdbS4W"
   },
   "source": [
    "# Download the datasets\n",
    "!test ! -e $drive_dataset_path \\\n",
    "  && bash datasets.sh > /dev/null"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6MYbVR-Gbqdr"
   },
   "source": [
    "# Preprocess the dataset and bake the augmentation variant\n",
    "!test ! -e $drive_dataset_path \\\n",
    "  && python preprocess.py --process_tvhi=True \\\n",
    "  && python bake.py --augment_repeat_count=25 --bake_input=datasets/TV-HI/data --bake_output=datasets/TV-HI/baked --bake_optical_flow=True"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GJDXKjjPrmIp"
   },
   "source": [
    "#@title Cache the processed dataset { display-mode: \"form\" }\n",
    "dataset_dir = \"datasets/TV-HI/baked*\" #@param {type:\"string\"}\n",
    "!test ! -e $drive_dataset_path \\\n",
    "  && echo 'Compressing the dataset' \\\n",
    "  && GZIP=-9 tar --totals=USR1 -czf $dataset_name $dataset_dir \\\n",
    "  && echo 'Copying cache to drive' \\\n",
    "  && cp $dataset_name $drive_dataset_path"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZITxolD3cJOG"
   },
   "source": [
    "# %env PROFILE_TF=1\n",
    "%env WANDB_START_METHOD=thread\n",
    "!python train_of.py --run_name='of_tvhi' --batch_size=128 --model_name='frames_stanford_v2'"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vdj1ByjPdJPZ"
   },
   "source": [
    "# %env PROFILE_TF=1\n",
    "%env WANDB_START_METHOD=thread\n",
    "!python train_of.py --run_name='of_tvhi' --batch_size=128 --model_name='frames_stanford_v2' --lr_step_size=500"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3QdMqHmwv_6T"
   },
   "source": [
    "# %env PROFILE_TF=1\n",
    "%env WANDB_START_METHOD=thread\n",
    "!python train_of.py --run_name='of_tvhi' --batch_size=128 --model_name='frames_stanford_v2' --lr_step_size=600"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bqj3-9BdOjX4"
   },
   "source": [
    "# %env PROFILE_TF=1\n",
    "%env WANDB_START_METHOD=thread\n",
    "!python train_of.py --run_name='of_tvhi' --batch_size=128 --model_name='frames_stanford_v2' --lr_step_size=1000"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oEUkA6nIOvh2"
   },
   "source": [
    "# %env PROFILE_TF=1\n",
    "%env WANDB_START_METHOD=thread\n",
    "!python train_of.py --run_name='of_tvhi' --batch_size=128 --model_name='frames_stanford_v2' --lr_step_size=400 --seed=1337"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mt4bzZy6V4CK"
   },
   "source": [
    "# %env PROFILE_TF=1\n",
    "%env WANDB_START_METHOD=thread\n",
    "!python train_of.py --run_name='of_tvhi' --batch_size=128 --model_name='frames_stanford_v2' --lr_step_size=300 --seed=1337"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mwB8BGWoV8uK"
   },
   "source": [
    "!python train_fusion.py --run_name='fusion_tvhi' --batch_size=128 --model_name='fusion_b67' \\\n",
    "  --fusion_frames_weights=snapshots/model_frames_tvhi_frames_stanford_v2.h5 \\\n",
    "  --fusion_of_weights=snapshots/model_of_tvhi_frames_stanford_v2.h5"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dDDpjKQUiujX"
   },
   "source": [
    "!python train_fusion.py --run_name='fusion_tvhi' --batch_size=128 --model_name='fusion_layerless' \\\n",
    "  --fusion_frames_weights=snapshots/model_frames_tvhi_frames_stanford_v2.h5 \\\n",
    "  --fusion_of_weights=snapshots/model_of_tvhi_frames_stanford_v2.h5 \\\n",
    "  --lr_step_size=500"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SK11aTsQjHyz"
   },
   "source": [
    "!python train_fusion.py --run_name='fusion_tvhi' --batch_size=128 --model_name='fusion_layerless' \\\n",
    "  --fusion_frames_weights=snapshots/model_frames_tvhi_frames_stanford_v2.h5 \\\n",
    "  --fusion_of_weights=snapshots/model_of_tvhi_frames_stanford_v2.h5 \\\n",
    "  --lr_step_size=300"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JcQfnTNLuMSc"
   },
   "source": [
    "!python train_fusion.py --run_name='fusion_tvhi' --batch_size=128 --model_name='fusion_b67' \\\n",
    "  --fusion_frames_model_name=frames_stanford_half_v2 \\\n",
    "  --fusion_frames_weights=snapshots/model_frames_tvhi_frames_stanford_v2.h5 \\\n",
    "  --fusion_of_model_name=frames_stanford_half_v2 \\\n",
    "  --fusion_of_weights=snapshots/model_of_tvhi_frames_stanford_v2.h5 \\\n",
    "  --lr_step_size=300"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yDgqqUpVxTVU"
   },
   "source": [
    "!python train_fusion.py --run_name='fusion_tvhi' --batch_size=128 --model_name='fusion_layerless' \\\n",
    "  --fusion_frames_model_name=frames_stanford_half_v2 \\\n",
    "  --fusion_frames_weights=snapshots/model_frames_tvhi_frames_stanford_v2.h5 \\\n",
    "  --fusion_of_model_name=frames_stanford_half_v2 \\\n",
    "  --fusion_of_weights=snapshots/model_of_tvhi_frames_stanford_v2.h5 \\\n",
    "  --lr_step_size=300"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2FMHZjv-15sS"
   },
   "source": [
    "!python train_fusion.py --run_name='fusion_tvhi' --batch_size=128 --model_name='fusion_layerless' \\\n",
    "  --fusion_frames_weights=snapshots/model_frames_tvhi_frames_stanford_v2.h5 \\\n",
    "  --fusion_of_weights=snapshots/model_of_tvhi_frames_stanford_v2.h5 \\\n",
    "  --lr_step_size=400"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "y-ZPCzXs5uJO"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}